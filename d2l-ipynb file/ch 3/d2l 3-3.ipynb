{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f64dcf7",
      "metadata": {
        "id": "8f64dcf7"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7f49fe9c",
      "metadata": {
        "id": "7f49fe9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: d2l==1.0.0-alpha1.post0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (1.0.0a1.post0)\n",
            "Requirement already satisfied: gym in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from d2l==1.0.0-alpha1.post0) (0.26.2)\n",
            "Requirement already satisfied: requests in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from d2l==1.0.0-alpha1.post0) (2.28.1)\n",
            "Requirement already satisfied: matplotlib in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from d2l==1.0.0-alpha1.post0) (3.6.0)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from d2l==1.0.0-alpha1.post0) (0.1.6)\n",
            "Requirement already satisfied: pandas in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from d2l==1.0.0-alpha1.post0) (1.5.2)\n",
            "Requirement already satisfied: numpy in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from d2l==1.0.0-alpha1.post0) (1.23.3)\n",
            "Requirement already satisfied: jupyter in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from d2l==1.0.0-alpha1.post0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from gym->d2l==1.0.0-alpha1.post0) (2.2.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from gym->d2l==1.0.0-alpha1.post0) (0.0.8)\n",
            "Requirement already satisfied: ipykernel in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter->d2l==1.0.0-alpha1.post0) (6.16.0)\n",
            "Requirement already satisfied: jupyter-console in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter->d2l==1.0.0-alpha1.post0) (6.4.4)\n",
            "Requirement already satisfied: notebook in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter->d2l==1.0.0-alpha1.post0) (6.5.2)\n",
            "Requirement already satisfied: qtconsole in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.4.0)\n",
            "Requirement already satisfied: ipywidgets in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter->d2l==1.0.0-alpha1.post0) (8.0.2)\n",
            "Requirement already satisfied: nbconvert in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter->d2l==1.0.0-alpha1.post0) (7.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (4.37.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (9.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from matplotlib-inline->d2l==1.0.0-alpha1.post0) (5.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from pandas->d2l==1.0.0-alpha1.post0) (2022.6)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests->d2l==1.0.0-alpha1.post0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests->d2l==1.0.0-alpha1.post0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests->d2l==1.0.0-alpha1.post0) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests->d2l==1.0.0-alpha1.post0) (2022.9.24)\n",
            "Requirement already satisfied: six>=1.5 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->d2l==1.0.0-alpha1.post0) (1.16.0)\n",
            "Requirement already satisfied: nest-asyncio in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (1.5.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (7.3.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (24.0.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (1.6.3)\n",
            "Requirement already satisfied: psutil in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (5.9.2)\n",
            "Requirement already satisfied: appnope in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.1.3)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (8.5.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (6.2)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (3.0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (4.0.3)\n",
            "Requirement already satisfied: pygments in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter-console->jupyter->d2l==1.0.0-alpha1.post0) (2.13.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter-console->jupyter->d2l==1.0.0-alpha1.post0) (3.0.31)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (2.1.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (3.1.2)\n",
            "Requirement already satisfied: defusedxml in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (4.11.1)\n",
            "Requirement already satisfied: mistune<3,>=2.0.3 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (2.0.4)\n",
            "Requirement already satisfied: nbformat>=5.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (5.7.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.2.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (1.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (4.11.1)\n",
            "Requirement already satisfied: bleach in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (5.0.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.17.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.4.8)\n",
            "Requirement already satisfied: argon2-cffi in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (21.3.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.15.0)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from qtconsole->jupyter->d2l==1.0.0-alpha1.post0) (2.3.0)\n",
            "Requirement already satisfied: decorator in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.18.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (4.8.0)\n",
            "Requirement already satisfied: backcall in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Requirement already satisfied: stack-data in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.5.1)\n",
            "Requirement already satisfied: entrypoints in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.4)\n",
            "Requirement already satisfied: notebook-shim>=0.1.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.2.2)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.23.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (4.17.1)\n",
            "Requirement already satisfied: fastjsonschema in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (2.16.2)\n",
            "Requirement already satisfied: wcwidth in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->d2l==1.0.0-alpha1.post0) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter->d2l==1.0.0-alpha1.post0) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (2.3.2.post1)\n",
            "Requirement already satisfied: webencodings in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from bleach->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.8.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.19.2)\n",
            "Requirement already satisfied: websocket-client in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.4.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0-alpha1.post0) (3.6.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.15.1)\n",
            "Requirement already satisfied: asttokens in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.0.8)\n",
            "Requirement already satisfied: executing in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (1.1.0)\n",
            "Requirement already satisfied: pure-eval in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /Users/chocho/Library/r-miniconda-arm64/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12c41702",
      "metadata": {
        "id": "12c41702",
        "origin_pos": 1
      },
      "source": [
        "# Synthetic Regression Data\n",
        ":label:`sec_synthetic-regression-data`\n",
        "\n",
        "\n",
        "Machine learning is all about extracting information from data.\n",
        "So you might wonder, what could we possibly learn from synthetic data?\n",
        "While we might not care intrinsically about the patterns \n",
        "that we ourselves baked into an artificial data generating model,\n",
        "such datasets are nevertheless useful for didactic purposes,\n",
        "helping us to evaluate the properties of our learning \n",
        "algorithms and to confirm that our implementations work as expected.\n",
        "For example, if we create data for which the correct parameters are known *a priori*,\n",
        "then we can verify that our model can in fact recover them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6b31f44e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:30.696278Z",
          "iopub.status.busy": "2022-08-29T22:02:30.695733Z",
          "iopub.status.idle": "2022-08-29T22:02:32.637296Z",
          "shell.execute_reply": "2022-08-29T22:02:32.636220Z"
        },
        "id": "6b31f44e",
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b5e53153",
      "metadata": {
        "id": "b5e53153",
        "origin_pos": 5
      },
      "source": [
        "## Generating the Dataset\n",
        "\n",
        "For this example, we will work low-dimensional\n",
        "for succinctness.\n",
        "The following code snippet generates 1000 examples\n",
        "with 2-dimensional features drawn \n",
        "from a standard normal distribution.\n",
        "The resulting design matrix $\\mathbf{X}$\n",
        "belongs to $\\mathbb{R}^{1000 \\times 2}$. \n",
        "We generate each label by applying \n",
        "a *ground truth* linear function, \n",
        "corrupted them via additive noise $\\epsilon$, \n",
        "drawn independently and identically for each example:\n",
        "\n",
        "$$\n",
        "\\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\mathbf\\epsilon.\n",
        "$$\n",
        "\n",
        "For convenience we assume that $\\epsilon$ is drawn \n",
        "from a normal distribution with mean $\\mu= 0$ \n",
        "and standard deviation $\\sigma = 0.01$.\n",
        "\n",
        "- Note that for object-oriented design\n",
        "we add the code to the `__init__` method of a subclass of `d2l.DataModule` (introduced in :numref:`oo-design-data`). \n",
        "\n",
        "- It's good practice to allow setting any additional hyperparameters. \n",
        "We accomplish this with `save_hyperparameters()`. \n",
        "The `batch_size` will be determined later on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c0cbd28",
      "metadata": {
        "id": "7c0cbd28",
        "origin_pos": 7
      },
      "source": [
        "Below, we set the true parameters to $\\mathbf{w} = [2, -3.4]^\\top$ and $b = 4.2$.\n",
        "Later, we can check our estimated parameters against these *ground truth* values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8717f53d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:32.651442Z",
          "iopub.status.busy": "2022-08-29T22:02:32.650715Z",
          "iopub.status.idle": "2022-08-29T22:02:32.657490Z",
          "shell.execute_reply": "2022-08-29T22:02:32.656424Z"
        },
        "id": "8717f53d",
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "data = SyntheticRegressionData(w=torch.tensor([2, -3.4]), b=4.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c1f92f15",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.1910, -1.0912],\n",
              "         [ 1.0457, -0.4085],\n",
              "         [-1.9408,  0.6971],\n",
              "         ...,\n",
              "         [ 2.0278,  1.3265],\n",
              "         [-0.7992, -0.1825],\n",
              "         [-1.3803, -0.8651]]),\n",
              " tensor([[ 8.2957],\n",
              "         [ 7.6946],\n",
              "         [-2.0524],\n",
              "         ...,\n",
              "         [ 3.7484],\n",
              "         [ 3.2150],\n",
              "         [ 4.3921]]))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.X, data.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "3e78c8af",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class SyntheticRegressionData(d2l.DataModule):  #@save\n",
        "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n",
        "                 batch_size=32):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        n = num_train + num_val\n",
        "        self.X = torch.randn(n, len(w))\n",
        "        noise = torch.randn(n, 1) * noise\n",
        "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise\n",
        "data = SyntheticRegressionData(w=torch.tensor([2, -3.4]), b=4.2)\n",
        "data.noise"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7eed0142",
      "metadata": {
        "id": "7eed0142",
        "origin_pos": 9
      },
      "source": [
        "Each row in `features` consists of a vector in $\\mathbb{R}^2$ and each row in `labels` is a scalar.\n",
        "Let's have a look at the first entry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "3c5a7c83",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:32.661369Z",
          "iopub.status.busy": "2022-08-29T22:02:32.660561Z",
          "iopub.status.idle": "2022-08-29T22:02:32.667708Z",
          "shell.execute_reply": "2022-08-29T22:02:32.666693Z"
        },
        "id": "3c5a7c83",
        "origin_pos": 10,
        "outputId": "2dfea958-a293-4deb-c79d-902aa8d8670d",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features: tensor([-0.4104,  0.1957]) \n",
            "label: tensor([2.7090])\n"
          ]
        }
      ],
      "source": [
        "print('features:', data.X[0],'\\nlabel:', data.y[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d3987970",
      "metadata": {
        "id": "d3987970",
        "origin_pos": 11
      },
      "source": [
        "## Reading the Dataset\n",
        "\n",
        "- Training machine learning models often requires multiple passes over a dataset,\n",
        "grabbing one minibatch of examples at a time.\n",
        "This data is then used to update the model.\n",
        "\n",
        "- To illustrate how this works, \n",
        "we implement the `get_dataloader` function,\n",
        "registering it as a method in the `SyntheticRegressionData` class via `add_to_class` \n",
        "(introduced in :numref:`oo-design-utilities`).\n",
        "\n",
        "- It takes a batch size, a matrix of features,\n",
        "and a vector of labels, and generates minibatches of size `batch_size`.\n",
        "As such, each minibatch consists of a tuple of features and labels. \n",
        "\n",
        "- Note that we need to be mindful of whether we're in training or validation mode: \n",
        "in the former, \n",
        "we will want to read the data in random order, \n",
        "whereas for the latter,\n",
        "being able to read data in a pre-defined order may be important for debugging purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "68ff44a7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:32.671639Z",
          "iopub.status.busy": "2022-08-29T22:02:32.670893Z",
          "iopub.status.idle": "2022-08-29T22:02:32.677048Z",
          "shell.execute_reply": "2022-08-29T22:02:32.676036Z"
        },
        "id": "68ff44a7",
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(SyntheticRegressionData)\n",
        "def get_dataloader(self, train):\n",
        "    if train:\n",
        "        indices = list(range(0, self.num_train))\n",
        "        # The examples are read in random order\n",
        "        random.shuffle(indices)\n",
        "    else:\n",
        "        indices = list(range(self.num_train, self.num_train+self.num_val))\n",
        "    for i in range(0, len(indices), self.batch_size):\n",
        "        batch_indices = torch.tensor(indices[i: i+self.batch_size])\n",
        "        yield self.X[batch_indices], self.y[batch_indices]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b7a56540",
      "metadata": {},
      "source": [
        "- https://ithelp.ithome.com.tw/articles/10258195"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "1c0ac54e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def yield_test(n):\n",
        "    print(\"start n =\", n)\n",
        "    for i in range(n):\n",
        "        yield i*i\n",
        "        print(\"i =\", i) # 最後一項時只會執行到 yield 不會繼續下去，所以後面的\n",
        "    print(\"end\")\n",
        "tests = yield_test(3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3e1752b2",
      "metadata": {},
      "source": [
        "- 執行三次可看出作用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "626ae4e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start n = 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "626ae4e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i = 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "626ae4e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i = 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "626ae4e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i = 2\n",
            "end\n"
          ]
        },
        {
          "ename": "StopIteration",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mnext\u001b[39m(tests)\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ],
      "source": [
        "next(tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "702acbe1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start n = 3\n",
            "yield:  0\n",
            "--------\n",
            "i = 0\n",
            "yield:  1\n",
            "--------\n",
            "i = 1\n",
            "yield:  4\n",
            "--------\n",
            "i = 2\n",
            "end\n"
          ]
        }
      ],
      "source": [
        "for test in tests:\n",
        "    print(\"yield: \", test)\n",
        "    print(\"--------\")\n",
        "tests = yield_test(3)\n",
        "for test in tests:\n",
        "    print(\"yield: \", test)\n",
        "    print(\"--------\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "aa050b5d",
      "metadata": {
        "id": "aa050b5d",
        "origin_pos": 13
      },
      "source": [
        "To build some intuition, \n",
        "let's inspect the first minibatch of data. \n",
        "Each minibatch of features provides us with both its size and the dimensionality of input features.\n",
        "Likewise, our minibatch of labels will have a matching shape given by `batch_size`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "1c30bf74",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-1.7844,  0.4149],\n",
              "         [-0.1671, -0.2875],\n",
              "         [-1.4256,  0.9691],\n",
              "         [-0.3123,  0.0596],\n",
              "         [-0.1961,  0.0438],\n",
              "         [-0.1566, -1.3969],\n",
              "         [ 0.3577, -2.1297],\n",
              "         [ 0.2844, -0.3421],\n",
              "         [ 0.1227,  1.0142],\n",
              "         [-0.1211,  0.6842],\n",
              "         [ 1.1255, -0.3765],\n",
              "         [-1.7070,  1.1289],\n",
              "         [-0.7528,  0.4416],\n",
              "         [ 0.1696,  0.1785],\n",
              "         [ 0.5595,  0.1191],\n",
              "         [-1.3201, -0.3713],\n",
              "         [-0.8688,  0.4932],\n",
              "         [ 0.7638,  0.0989],\n",
              "         [ 0.5768,  0.4609],\n",
              "         [-0.5516,  0.5005],\n",
              "         [-0.1589,  0.1175],\n",
              "         [ 0.1363,  0.0227],\n",
              "         [-0.6584,  0.0261],\n",
              "         [-2.1747,  1.4089],\n",
              "         [ 0.5673,  0.0193],\n",
              "         [ 0.9940, -0.2829],\n",
              "         [-1.4849, -0.5273],\n",
              "         [-0.8087,  1.0222],\n",
              "         [ 1.5681,  0.8228],\n",
              "         [ 0.0061, -0.1476],\n",
              "         [-0.6502, -0.0146],\n",
              "         [ 0.7585, -1.0735]]),\n",
              " tensor([[-0.7862],\n",
              "         [ 4.8398],\n",
              "         [-1.9520],\n",
              "         [ 3.3819],\n",
              "         [ 3.6600],\n",
              "         [ 8.6350],\n",
              "         [12.1767],\n",
              "         [ 5.9343],\n",
              "         [ 0.9912],\n",
              "         [ 1.6536],\n",
              "         [ 7.7246],\n",
              "         [-3.0514],\n",
              "         [ 1.2047],\n",
              "         [ 3.9212],\n",
              "         [ 4.8892],\n",
              "         [ 2.8246],\n",
              "         [ 0.7851],\n",
              "         [ 5.3922],\n",
              "         [ 3.7766],\n",
              "         [ 1.3872],\n",
              "         [ 3.5008],\n",
              "         [ 4.3852],\n",
              "         [ 2.8007],\n",
              "         [-4.9400],\n",
              "         [ 5.2772],\n",
              "         [ 7.1546],\n",
              "         [ 3.0162],\n",
              "         [-0.9036],\n",
              "         [ 4.5558],\n",
              "         [ 4.7191],\n",
              "         [ 2.9354],\n",
              "         [ 9.3647]]))"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(data.train_dataloader())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "2706268f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:32.680638Z",
          "iopub.status.busy": "2022-08-29T22:02:32.680119Z",
          "iopub.status.idle": "2022-08-29T22:02:32.686113Z",
          "shell.execute_reply": "2022-08-29T22:02:32.685112Z"
        },
        "id": "2706268f",
        "origin_pos": 14,
        "outputId": "4d225837-223a-43d9-d813-579df4c08efc",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([32, 2]) \n",
            "y shape: torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(data.train_dataloader()))\n",
        "print('X shape:', X.shape, '\\ny shape:', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "737dad7c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.6166,  0.7362],\n",
              "         [-2.1747,  1.4089],\n",
              "         [ 0.3780,  1.4513],\n",
              "         [-0.6670, -0.3031],\n",
              "         [-0.4569, -0.3421],\n",
              "         [ 1.4955, -0.2919],\n",
              "         [ 0.7895, -0.8221],\n",
              "         [-0.2102,  1.9559],\n",
              "         [-1.2427, -0.4630],\n",
              "         [ 0.7638,  0.0989],\n",
              "         [-0.0209, -0.1050],\n",
              "         [-0.8688,  0.4932],\n",
              "         [ 1.4120, -1.0275],\n",
              "         [-0.8697, -0.5213],\n",
              "         [-0.9751,  1.1446],\n",
              "         [-1.5455,  0.9903],\n",
              "         [ 2.3733,  0.0521],\n",
              "         [-0.5018, -0.1240],\n",
              "         [-2.2299,  1.8953],\n",
              "         [-0.2458,  1.6103],\n",
              "         [-0.0595, -0.0132],\n",
              "         [-0.9496, -0.6938],\n",
              "         [ 1.5717,  0.2121],\n",
              "         [-0.4800, -0.5913],\n",
              "         [ 2.4407,  0.8867],\n",
              "         [ 0.6126, -0.7681],\n",
              "         [-0.8624,  0.7481],\n",
              "         [-0.7180,  0.8703],\n",
              "         [-0.4481, -1.3920],\n",
              "         [-1.9863, -0.6960],\n",
              "         [ 0.7544,  0.0977],\n",
              "         [ 0.8523,  1.4298]]),\n",
              " tensor([[ 2.9300],\n",
              "         [-4.9400],\n",
              "         [ 0.0208],\n",
              "         [ 3.8867],\n",
              "         [ 4.4362],\n",
              "         [ 8.1783],\n",
              "         [ 8.5762],\n",
              "         [-2.8839],\n",
              "         [ 3.2752],\n",
              "         [ 5.3922],\n",
              "         [ 4.5115],\n",
              "         [ 0.7851],\n",
              "         [10.5170],\n",
              "         [ 4.2229],\n",
              "         [-1.6289],\n",
              "         [-2.2609],\n",
              "         [ 8.7702],\n",
              "         [ 3.6240],\n",
              "         [-6.7152],\n",
              "         [-1.7644],\n",
              "         [ 4.1374],\n",
              "         [ 4.6603],\n",
              "         [ 6.6161],\n",
              "         [ 5.2644],\n",
              "         [ 6.0644],\n",
              "         [ 8.0303],\n",
              "         [-0.0556],\n",
              "         [-0.1985],\n",
              "         [ 8.0516],\n",
              "         [ 2.5895],\n",
              "         [ 5.3559],\n",
              "         [ 1.0686]]))"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(data.train_dataloader())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2ab5ee02",
      "metadata": {},
      "source": [
        "[迭代器與生成器](https://www.runoob.com/python3/python3-iterator-generator.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "9d773eaa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "List=[1,2,3,4]\n",
        "it = iter(List)    # 创建迭代器对象\n",
        "next(it)\n",
        "next(it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "24442351",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "24442351",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "24442351",
      "metadata": {},
      "outputs": [
        {
          "ename": "StopIteration",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mnext\u001b[39m(it)\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ],
      "source": [
        "next(it)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1a3193e0",
      "metadata": {
        "id": "1a3193e0",
        "origin_pos": 15
      },
      "source": [
        "While seemingly innocuous, the invocation of `iter(data.train_dataloader())` \n",
        "illustrates the power of Python's object-oriented design. \n",
        "Note that we added a method to the `SyntheticRegressionData` class\n",
        "*after* creating the `data` object. \n",
        "Nonetheless, the object benefits from \n",
        "the *ex post facto* addition of functionality to the class.\n",
        "\n",
        "Throughout the iteration we obtain distinct minibatches until the entire dataset has been exhausted (try this).\n",
        "While the iteration implemented above is good for didactic purposes,\n",
        "it is inefficient in ways that might get us in trouble on real problems.\n",
        "For example, it requires that we load all the data in memory\n",
        "and that we perform lots of random memory access.\n",
        "The built-in iterators implemented in a deep learning framework\n",
        "are considerably more efficient and they can deal\n",
        "with sources such as data stored in files, \n",
        "data received via a stream, \n",
        "and data generated or processed on the fly. \n",
        "Next let's try to implement the same function using built-in iterators."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "12c72f03",
      "metadata": {},
      "source": [
        "## Concise Implementation of the Data Loader\n",
        "\n",
        "Rather than writing our own iterator,\n",
        "we can call the existing API in a framework to load data.\n",
        "\n",
        "As before, we need a dataset with features `X` and labels `y`. \n",
        "\n",
        "Beyond that, we set `batch_size` in the built-in data loader \n",
        "and let it take care of shuffling examples  efficiently.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1736ce9a",
      "metadata": {},
      "source": [
        "- https://www.runoob.com/python/python-func-slice.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "5375879a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "3\n",
            "6\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "myslice = slice(None,None,3)\n",
        "for i in range(10)[myslice]:\n",
        "    print(i)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ecfa1df3",
      "metadata": {},
      "source": [
        "- https://pytorch.org/docs/stable/data.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "fad3fb3e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:32.689550Z",
          "iopub.status.busy": "2022-08-29T22:02:32.689078Z",
          "iopub.status.idle": "2022-08-29T22:02:32.695696Z",
          "shell.execute_reply": "2022-08-29T22:02:32.694577Z"
        },
        "id": "fad3fb3e",
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(d2l.DataModule)  #@save\n",
        "def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
        "    tensors = tuple(a[indices] for a in tensors)\n",
        "    dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "    return torch.utils.data.DataLoader(dataset, self.batch_size,\n",
        "                                       shuffle=train)\n",
        "@d2l.add_to_class(SyntheticRegressionData)  #@save\n",
        "def get_dataloader(self, train):\n",
        "    i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
        "    return self.get_tensorloader((self.X, self.y), train, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec9c2c69",
      "metadata": {
        "id": "ec9c2c69",
        "origin_pos": 17
      },
      "source": [
        "The new data loader behaves just as the previous one, except that it is more efficient and has some added functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d42e184",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "4"
        },
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:32.699493Z",
          "iopub.status.busy": "2022-08-29T22:02:32.698804Z",
          "iopub.status.idle": "2022-08-29T22:02:32.705636Z",
          "shell.execute_reply": "2022-08-29T22:02:32.704588Z"
        },
        "id": "2d42e184",
        "origin_pos": 18,
        "outputId": "749a5d5e-cd31-47ca-fdec-412ad27acad1",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([32, 2]) \n",
            "y shape: torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(data.train_dataloader()))\n",
        "print('X shape:', X.shape, '\\ny shape:', y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b10a84d",
      "metadata": {
        "id": "8b10a84d",
        "origin_pos": 19
      },
      "source": [
        "For instance, the data loader provided by the framework API \n",
        "supports the built-in `__len__` method, \n",
        "so we can query its length, \n",
        "i.e., the number of batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0d01aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-29T22:02:32.709413Z",
          "iopub.status.busy": "2022-08-29T22:02:32.708676Z",
          "iopub.status.idle": "2022-08-29T22:02:32.716692Z",
          "shell.execute_reply": "2022-08-29T22:02:32.715640Z"
        },
        "id": "4a0d01aa",
        "origin_pos": 20,
        "outputId": "501b60f2-5fee-4cbf-9351-a1ec2f20ff80",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data.train_dataloader())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "66cfb787",
      "metadata": {
        "id": "66cfb787",
        "origin_pos": 21
      },
      "source": [
        "## Summary\n",
        "\n",
        "Data loaders are a convenient way of abstracting out \n",
        "the process of loading and manipulating data. \n",
        "\n",
        "This way the same machine learning *algorithm* \n",
        "is capable of processing many different types and sources of data \n",
        "without the need for modification. \n",
        "\n",
        "One of the nice things about data loaders \n",
        "is that they can be composed. \n",
        "\n",
        "For instance, we might be loading images \n",
        "and then have a post-processing filter \n",
        "that crops them or modifies them otherwise. \n",
        "\n",
        "As such, data loaders can be used \n",
        "to describe an entire data processing pipeline. \n",
        "\n",
        "As for the model itself, the two-dimensional linear model \n",
        "is about as simple a model as we might encounter. \n",
        "\n",
        "It lets us test out the accuracy of regression models \n",
        "without worry about having insufficient amounts of data \n",
        "or an underdetermined system of equations. \n",
        "\n",
        "We will put this to good use in the next section.  \n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. What will happen if the number of examples cannot be divided by the batch size. How to change this behavior by specifying a different argument by using framework's API?\n",
        "1. What if we want to generate a huge dataset, where both the size of the parameter vector `w` and the number of examples `num_examples` are large? \n",
        "    1. What happens if we cannot hold all data in memory?\n",
        "    1. How would you shuffle the data if data is held on disk? Your task is to design an *efficient* algorithm that does not require too many random reads or writes. Hint: [pseudorandom permutation generators](https://en.wikipedia.org/wiki/Pseudorandom_permutation) allow you to design a reshuffle without the need to store the permutation table explicitly :cite:`Naor.Reingold.1999`. \n",
        "1. Implement a data generator that produces new data on the fly, every time the iterator is called. \n",
        "1. How would you design a random data generator that generates *the same* data each time it's called?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d002bb",
      "metadata": {
        "id": "76d002bb",
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ]
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/6663)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "924b4310eef0a4626e6be183858539210ebddb9168f6747ddef9ed01eb54dbfb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
